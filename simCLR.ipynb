{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import  DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from dataset import ContrastiveDataset\n",
    "from optimizer import LARS\n",
    "from loss import NT_Xent\n",
    "from model import BackboneModel\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1117856b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42 \n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader for self-supervised case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "cifar_train = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "cifar_test = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_img_array = np.array([np.array(image) for image, _ in cifar_train])\n",
    "test_img_array = np.array([np.array(image) for image, _ in cifar_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ContrastiveDataset(\"train\", train_img_array[:40000])\n",
    "val_dataset = ContrastiveDataset(\"val\", train_img_array[40000:])\n",
    "test_dataset = ContrastiveDataset(\"test\", train_img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_batch_size = 128\n",
    "num_workers = 0 # means no sub-processes, needed for debugging\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=ssl_batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=ssl_batch_size, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=ssl_batch_size, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BackboneModel().to(device)\n",
    "optimizer = LARS(\n",
    "    [params for params in model.parameters() if params.requires_grad],\n",
    "    lr=0.2,\n",
    "    weight_decay=1e-6,\n",
    "    exclude_from_weight_decay=[\"batch_normalization\", \"bias\"],\n",
    ")\n",
    "criterion = NT_Xent(batch_size=ssl_batch_size, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarl/.virtualenvs/specialization_project/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, training loss: 0.01732151043681672, validation loss: 0.0688595590712149\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs): \n",
    "\n",
    "  model.train()\n",
    "  training_loss = 0\n",
    "  for (x_i, x_j) in train_dataloader: \n",
    "    optimizer.zero_grad()\n",
    "    x_i, x_j = x_i.to(device), x_j.to(device)\n",
    "\n",
    "    z_i = model(x_i)\n",
    "    z_j = model(x_j)\n",
    "\n",
    "    loss = criterion(z_i, z_j)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    training_loss += loss.item()\n",
    "    break # TODO: Remove this when actually training\n",
    "  \n",
    "  training_loss /= len(train_dataloader)\n",
    "  \n",
    "  model.eval()\n",
    "  with torch.no_grad(): \n",
    "    validation_loss = 0\n",
    "    for (x_i, x_j) in val_dataloader: \n",
    "      x_i, x_j = x_i.to(device), x_j.to(device)\n",
    "\n",
    "      z_i = model(x_i)\n",
    "      z_j = model(x_j)\n",
    "\n",
    "      loss = criterion(z_i, z_j)\n",
    "      validation_loss += loss.item()\n",
    "      break # TODO: Remove this when actually training\n",
    "\n",
    "    validation_loss /= len(val_dataloader)\n",
    "    \n",
    "    print(f\"Epoch #{epoch}, training loss: {training_loss}, validation loss: {validation_loss}\")\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to file\n",
    "model_path = \"models/simclr.pth\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    model_path,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
